{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eebe3c1",
   "metadata": {},
   "source": [
    "# Test my shit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0725efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================================================\n",
    "# Goal: Test dimension matrix\n",
    "# Check:\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# =================================================================================================================\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.unitary_matrix_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0c2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_index = 800\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed01f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================================================\n",
    "# =========================================== HYPARAMETERS ========================================================\n",
    "# =================================================================================================================\n",
    "# Each CPU run 10 repetitions and 10 different matrices\n",
    "n_CPU_X_sim = 100\n",
    "n_matrix_x_CPU = 10\n",
    "n_repetitions = 10\n",
    "\n",
    "configs = [\n",
    "    {\"index\": 0, \"model_obj\": Clements_Arct, \"type_lim\": \"clamp_ste\"},\n",
    "    {\"index\": 1, \"model_obj\": Clements_Arct, \"type_lim\": \"clamp\"},\n",
    "    {\"index\": 2, \"model_obj\": Clements_Arct, \"type_lim\": \"tanh_soft\"},\n",
    "    {\"index\": 3, \"model_obj\": Clements_Arct, \"type_lim\": \"tanh_hard\"},\n",
    "    \n",
    "    {\"index\": 4, \"model_obj\": Fldzhyan_Arct, \"type_lim\": \"clamp_ste\"},\n",
    "    {\"index\": 5, \"model_obj\": Fldzhyan_Arct, \"type_lim\": \"clamp\"},\n",
    "    {\"index\": 6, \"model_obj\": Fldzhyan_Arct, \"type_lim\": \"tanh_soft\"},\n",
    "    {\"index\": 7, \"model_obj\": Fldzhyan_Arct, \"type_lim\": \"tanh_hard\"},\n",
    "    \n",
    "    {\"index\": 8, \"model_obj\": NEUROPULSCrossingSide_Arct, \"type_lim\": \"clamp_ste\"},\n",
    "    {\"index\": 9, \"model_obj\": NEUROPULSCrossingSide_Arct, \"type_lim\": \"clamp\"},\n",
    "    {\"index\": 10, \"model_obj\": NEUROPULSCrossingSide_Arct, \"type_lim\": \"tanh_soft\"},\n",
    "    {\"index\": 11, \"model_obj\": NEUROPULSCrossingSide_Arct, \"type_lim\": \"tanh_hard\"},\n",
    "]\n",
    "\n",
    "# Each CPU\n",
    "search_index = run_index // n_CPU_X_sim\n",
    "config = next(c for c in configs if c[\"index\"] == search_index)\n",
    "model_obj = config[\"model_obj\"]\n",
    "num_folder = config[\"index\"]\n",
    "type_lim = config[\"type_lim\"]\n",
    "\n",
    "# =================================================================================================================\n",
    "n_inputs = 8\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 500 * n_inputs + 18000\n",
    "\n",
    "# GAUSSIAN DISTRIBUTION\n",
    "pc_iloss_mu = 0.\n",
    "pc_iloss_sigma = 0.\n",
    "i_loss_MMI_mu = 0.\n",
    "i_loss_MMI_sigma = 0.\n",
    "imbalance_mu = 0.\n",
    "imbalance_sigma = 0.\n",
    "i_loss_Crossing_mu = 0.\n",
    "i_loss_Crossing_sigma = 0.\n",
    "cross_talk_mu = -1000.\n",
    "cross_talk_sigma = 0.\n",
    "\n",
    "# pc_iloss_mu = 0.        # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# pc_iloss_sigma = 0.     # Std deviation\n",
    "\n",
    "# i_loss_MMI_mu = -0.5          # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# i_loss_MMI_sigma = 0.1       # Std deviation\n",
    "# imbalance_mu = 0.           # Average =P_outmax/P_outmin. 0dB 50/50 MMI, 100dB all power to outUP, -100dB all power to outDOWN\n",
    "# imbalance_sigma = 0.15        # Std deviation\n",
    "\n",
    "# i_loss_Crossing_mu = -0.2         # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# i_loss_Crossing_sigma = 0.05      # Std deviation\n",
    "# cross_talk_mu = -35.          # Average =P_leakout/P_otherout. -infdB Crossing perfect, -1dB very bad device a lot power leak\n",
    "# cross_talk_sigma = 1.           # Std deviation\n",
    "\n",
    "# =================================================================================================================\n",
    "# =================================================================================================================\n",
    "# ================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5e2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the right target -------------------------------------------------------------------------------------------\n",
    "def load_targets(index_matrix, n_inputs):\n",
    "    all_target = torch.load(\"./dataset/targets_nIN\"+str(n_inputs)+\"_nM1000.pt\", weights_only=False)\n",
    "    target_matricies = all_target[index_matrix*n_matrix_x_CPU:(index_matrix+1)*n_matrix_x_CPU, : , :]\n",
    "    return target_matricies\n",
    "\n",
    "# Select model ----------------------------------------------------------------------------------------------------\n",
    "# Truncate the gaussian distribution\n",
    "def create_truncated_gaussian_tensor(mu, sigma, shape, max_value=None):\n",
    "    tensor = torch.normal(mean=mu, std=sigma, size=shape)\n",
    "    if max_value is not None:\n",
    "        tensor = torch.clamp(tensor, max=max_value)\n",
    "    return tensor\n",
    "\n",
    "def select_model(name_model):\n",
    "    mmi_i_losses_mtx_even = create_truncated_gaussian_tensor(i_loss_MMI_mu, i_loss_MMI_sigma, (2*(n_inputs-1), n_inputs//2), 0)\n",
    "    mmi_i_losses_mtx_even = 10**(mmi_i_losses_mtx_even/10)\n",
    "    mmi_i_losses_mtx_odd = create_truncated_gaussian_tensor(i_loss_MMI_mu, i_loss_MMI_sigma, (n_inputs, n_inputs//2-1), 0)\n",
    "    mmi_i_losses_mtx_odd = 10**(mmi_i_losses_mtx_odd/10)\n",
    "    mmi_imbalances_mtx_even = create_truncated_gaussian_tensor(imbalance_mu, imbalance_sigma, (2*(n_inputs-1), n_inputs//2))\n",
    "    mmi_imbalances_mtx_even = 10**(mmi_imbalances_mtx_even/10)\n",
    "    mmi_imbalances_mtx_odd = create_truncated_gaussian_tensor(imbalance_mu, imbalance_sigma, (n_inputs, n_inputs//2-1))\n",
    "    mmi_imbalances_mtx_odd = 10**(mmi_imbalances_mtx_odd/10)\n",
    "\n",
    "    crossing_i_losses_mtx_odd = create_truncated_gaussian_tensor(i_loss_Crossing_mu, i_loss_Crossing_sigma, (n_inputs-2, n_inputs//2-1), 0)\n",
    "    crossing_i_losses_mtx_odd = 10**(crossing_i_losses_mtx_odd/10)\n",
    "    crossing_i_losses_mtx_odd_side = create_truncated_gaussian_tensor(i_loss_Crossing_mu, i_loss_Crossing_sigma, (n_inputs-2, n_inputs//2+1), 0)\n",
    "    crossing_i_losses_mtx_odd_side = 10**(crossing_i_losses_mtx_odd_side/10)\n",
    "    crossing_crosstalks_mtx_odd = create_truncated_gaussian_tensor(cross_talk_mu, cross_talk_sigma, (n_inputs-2, n_inputs//2-1))\n",
    "    crossing_crosstalks_mtx_odd = 10**(crossing_crosstalks_mtx_odd/10)\n",
    "    crossing_crosstalks_mtx_odd_side = create_truncated_gaussian_tensor(cross_talk_mu, cross_talk_sigma, (n_inputs-2, n_inputs//2+1))\n",
    "    crossing_crosstalks_mtx_odd_side = 10**(crossing_crosstalks_mtx_odd_side/10)\n",
    "\n",
    "    if name_model == Clements_Arct:\n",
    "        model = Clements_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_i_losses_mtx_odd=mmi_i_losses_mtx_odd,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            mmi_imbalances_mtx_odd=mmi_imbalances_mtx_odd,\n",
    "            type_lim=type_lim)\n",
    "    elif name_model == Fldzhyan_Arct:\n",
    "        model = Fldzhyan_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_i_losses_mtx_odd=mmi_i_losses_mtx_odd,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            mmi_imbalances_mtx_odd=mmi_imbalances_mtx_odd,\n",
    "            type_lim=type_lim)\n",
    "    elif name_model == NEUROPULSCrossingSide_Arct:\n",
    "        model = NEUROPULSCrossingSide_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            crossing_i_losses_mtx_odd=crossing_i_losses_mtx_odd_side,\n",
    "            crossing_crosstalks_mtx_odd=crossing_crosstalks_mtx_odd_side,\n",
    "            type_lim=type_lim)\n",
    "    else:\n",
    "        model = None\n",
    "        raise Exception('Something not good on the input')\n",
    "    return model\n",
    "\n",
    "# Fidelity and Loss function --------------------------------------------------------------------------------------\n",
    "def FidelityUnitary(predicted_matrix, target_matrix):\n",
    "    n_inputs = predicted_matrix.shape[0]\n",
    "    predicted_matrix = predicted_matrix.to(torch.complex128)\n",
    "    target_matrix = target_matrix.to(torch.complex128)\n",
    "    Frobenius_module_p = torch.trace(torch.matmul(predicted_matrix.t().conj(), predicted_matrix))\n",
    "    Frobenius_pt = torch.trace(torch.matmul(predicted_matrix.t().conj(), target_matrix))\n",
    "    cosine_similarity = (torch.abs(Frobenius_pt))**2/(n_inputs*Frobenius_module_p)\n",
    "    Fidelity = torch.abs(cosine_similarity)\n",
    "    return Fidelity\n",
    "\n",
    "def Loss_FildelityUnitary(predicted_matrix, target_matrix):\n",
    "    fidelity = FidelityUnitary(predicted_matrix, target_matrix)\n",
    "    return 1 - fidelity\n",
    "\n",
    "# Calculate the prediction ----------------------------------------------------------------------------------------\n",
    "def model_training(model, optimizer, target_matrix):\n",
    "    for _ in range(n_epochs):     # Optimiziation with gradient\n",
    "        pred_matrix = model()\n",
    "        loss = Loss_FildelityUnitary(pred_matrix, target_matrix)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Get fidelity\n",
    "    with torch.no_grad():\n",
    "        pred_matrix = model()\n",
    "        fidelity = FidelityUnitary(pred_matrix, target_matrix)\n",
    "    return fidelity, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# =================================================================================================================\n",
    "# =============================================== MAIN ============================================================\n",
    "# =================================================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the right data\n",
    "    index_matrix = run_index % n_CPU_X_sim\n",
    "    targets = load_targets(index_matrix, n_inputs)\n",
    "\n",
    "    # Simulations\n",
    "    fidelities = []\n",
    "    n_targets = targets.shape[0]\n",
    "    for idx_targ in tqdm.trange(n_targets):\n",
    "        for rep in range(n_repetitions):\n",
    "            # Initialize new model with different initial phase shifts for each simulaiton\n",
    "            model = select_model(model_obj)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            last_fidelity, model = model_training(model, optimizer, targets[idx_targ, : , :])\n",
    "            fidelities.append(last_fidelity)\n",
    "\n",
    "            # chagne the phase shift gradually to see effect on fidelity\n",
    "    \n",
    "    # Save the results model ======================================================================================\n",
    "    # Create folder and retun the directory:\n",
    "    base_dir = \"./outdata/\"\n",
    "    # Create the new run directory\n",
    "    run_dir = os.path.join(base_dir, f'run{num_folder}')\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    # Create the full path\n",
    "    filename = f'simulation_{run_index}.pt'\n",
    "    full_path = os.path.join(run_dir, filename)\n",
    "    # Create a dictionary\n",
    "    save_dict = {\n",
    "        'model_name': model_obj.__name__,\n",
    "        'run_index': run_index,\n",
    "        'fidelities': fidelities,\n",
    "    }\n",
    "    # Save it\n",
    "    torch.save(save_dict, full_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    work_duration = end_time - start_time\n",
    "    max_duration_human_readable = str(timedelta(seconds=work_duration))\n",
    "    print(f\"The maximum work duration is {max_duration_human_readable} (HH:MM:SS).\")\n",
    "    \n",
    "    print(\"Yeeeeh the code has finished!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d1b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_NP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
