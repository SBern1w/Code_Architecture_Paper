{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eebe3c1",
   "metadata": {},
   "source": [
    "# Test my shit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0725efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================================================\n",
    "# Goal: Test losses PCM\n",
    "# Check:\n",
    "\n",
    "# TODO:\n",
    "\n",
    "# =================================================================================================================\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.unitary_matrix_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0c2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_index = 899\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed01f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================================================\n",
    "# =========================================== HYPARAMETERS ========================================================\n",
    "# =================================================================================================================\n",
    "# Each CPU run 10 repetitions and 10 different matrices\n",
    "n_CPU_X_sim = 100\n",
    "n_matrix_x_CPU = 10\n",
    "n_repetitions = 10\n",
    "\n",
    "configs = [\n",
    "    {\"index\": 0, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": 0.},\n",
    "    {\"index\": 1, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -0.1},\n",
    "    {\"index\": 2, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -0.2},\n",
    "    {\"index\": 3, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -0.5},\n",
    "    {\"index\": 4, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -0.75},\n",
    "    {\"index\": 5, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -1.},\n",
    "    {\"index\": 6, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -1.25},\n",
    "    {\"index\": 7, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -1.5},\n",
    "    {\"index\": 8, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -1.75},\n",
    "    {\"index\": 9, \"model_obj\": Clements_Arct, \"pc_loss_dB_max\": -2.},\n",
    "\n",
    "    {\"index\": 10, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": 0.},\n",
    "    {\"index\": 11, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -0.1},\n",
    "    {\"index\": 12, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -0.2},\n",
    "    {\"index\": 13, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -0.5},\n",
    "    {\"index\": 14, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -0.75},\n",
    "    {\"index\": 15, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -1.},\n",
    "    {\"index\": 16, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -1.25},\n",
    "    {\"index\": 17, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -1.5},\n",
    "    {\"index\": 18, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -1.75},\n",
    "    {\"index\": 19, \"model_obj\": Fldzhyan_Arct, \"pc_loss_dB_max\": -2.},\n",
    "\n",
    "    {\"index\": 20, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": 0.},\n",
    "    {\"index\": 21, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -0.1},\n",
    "    {\"index\": 22, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -0.2},\n",
    "    {\"index\": 23, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -0.5},\n",
    "    {\"index\": 24, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -0.75},\n",
    "    {\"index\": 25, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -1.},\n",
    "    {\"index\": 26, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -1.25},\n",
    "    {\"index\": 27, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -1.5},\n",
    "    {\"index\": 28, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -1.75},\n",
    "    {\"index\": 29, \"model_obj\": NEUROPULSCrossingSide_Arct, \"pc_loss_dB_max\": -2.},\n",
    "]\n",
    "\n",
    "# Each CPU\n",
    "search_index = run_index // n_CPU_X_sim\n",
    "config = next(c for c in configs if c[\"index\"] == search_index)\n",
    "model_obj = config[\"model_obj\"]\n",
    "num_folder = config[\"index\"]\n",
    "pc_loss_dB_max = config[\"pc_loss_dB_max\"]\n",
    "N_bits = 16\n",
    "phase_shift_noise_std = 0.\n",
    "\n",
    "# =================================================================================================================\n",
    "n_inputs = 8\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 500 * n_inputs + 18000\n",
    "\n",
    "# GAUSSIAN DISTRIBUTION\n",
    "# pc_iloss_mu = 0.        # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# pc_iloss_sigma = 0.5     # Std deviation\n",
    "\n",
    "# i_loss_MMI_mu = 0.5          # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# i_loss_MMI_sigma = 0.1       # Std deviation\n",
    "# imbalance_mu = 0.           # Average =P_outmax/P_outmin. 0dB 50/50 MMI, 100dB all power to outUP, -100dB all power to outDOWN\n",
    "# imbalance_sigma = 0.15        # Std deviation\n",
    "\n",
    "# i_loss_Crossing_mu = 0.2         # Average =P_out/P_in. 0dB pefect component, -100dB very lossy\n",
    "# i_loss_Crossing_sigma = 0.05      # Std deviation\n",
    "# cross_talk_mu = -35.          # Average =P_leakout/P_otherout. -infdB Crossing perfect, -1dB very bad device a lot power leak\n",
    "# cross_talk_sigma = 1.           # Std deviation\n",
    "pc_iloss_mu = 0.\n",
    "pc_iloss_sigma = 0.\n",
    "i_loss_MMI_mu = 0.\n",
    "i_loss_MMI_sigma = 0.\n",
    "imbalance_mu = 0.\n",
    "imbalance_sigma = 0.\n",
    "\n",
    "i_loss_Crossing_mu = 0.\n",
    "i_loss_Crossing_sigma = 0.\n",
    "cross_talk_mu = -1000.\n",
    "cross_talk_sigma = 0.\n",
    "\n",
    "# =================================================================================================================\n",
    "# =================================================================================================================\n",
    "# =================================================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5e2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the right target -------------------------------------------------------------------------------------------\n",
    "def load_targets(index_matrix):\n",
    "    all_target = torch.load(\"./dataset/targets_nIN8_nM1000.pt\", weights_only=False)\n",
    "    target_matricies = all_target[index_matrix*n_matrix_x_CPU:(index_matrix+1)*n_matrix_x_CPU, : , :]\n",
    "    return target_matricies\n",
    "\n",
    "# Select model ----------------------------------------------------------------------------------------------------\n",
    "# Truncate the gaussian distribution\n",
    "def create_truncated_gaussian_tensor(mu, sigma, shape, max_value=None):\n",
    "    tensor = torch.normal(mean=mu, std=sigma, size=shape)\n",
    "    if max_value is not None:\n",
    "        tensor = torch.clamp(tensor, max=max_value)\n",
    "    return tensor\n",
    "\n",
    "def select_model(name_model):\n",
    "    pc_i_losses_mtx_even = create_truncated_gaussian_tensor(pc_iloss_mu, pc_iloss_sigma, (2*(n_inputs-1), n_inputs), 0)\n",
    "    pc_i_losses_mtx_even = 10**(pc_i_losses_mtx_even/10)\n",
    "    pc_i_losses_mtx_odd = create_truncated_gaussian_tensor(pc_iloss_mu, pc_iloss_sigma, (n_inputs, n_inputs), 0)\n",
    "    pc_i_losses_mtx_odd = 10**(pc_i_losses_mtx_odd/10)\n",
    "    pc_i_losses_mtx_inout = create_truncated_gaussian_tensor(pc_iloss_mu, pc_iloss_sigma, (2, n_inputs), 0)\n",
    "    pc_i_losses_mtx_inout = 10**(pc_i_losses_mtx_inout/10)\n",
    "    pc_i_losses_mtx_full = create_truncated_gaussian_tensor(pc_iloss_mu, pc_iloss_sigma, (n_inputs, n_inputs), 0)\n",
    "    pc_i_losses_mtx_full = 10**(pc_i_losses_mtx_full/10)\n",
    "    pc_i_losses_mtx_side = create_truncated_gaussian_tensor(pc_iloss_mu, pc_iloss_sigma, (n_inputs-2, n_inputs), 0)\n",
    "    pc_i_losses_mtx_side = 10**(pc_i_losses_mtx_side/10)\n",
    "\n",
    "    mmi_i_losses_mtx_even = create_truncated_gaussian_tensor(i_loss_MMI_mu, i_loss_MMI_sigma, (2*(n_inputs-1), n_inputs//2), 0)\n",
    "    mmi_i_losses_mtx_even = 10**(mmi_i_losses_mtx_even/10)\n",
    "    mmi_i_losses_mtx_odd = create_truncated_gaussian_tensor(i_loss_MMI_mu, i_loss_MMI_sigma, (n_inputs, n_inputs//2-1), 0)\n",
    "    mmi_i_losses_mtx_odd = 10**(mmi_i_losses_mtx_odd/10)\n",
    "    mmi_imbalances_mtx_even = create_truncated_gaussian_tensor(imbalance_mu, imbalance_sigma, (2*(n_inputs-1), n_inputs//2))\n",
    "    mmi_imbalances_mtx_even = 10**(mmi_imbalances_mtx_even/10)\n",
    "    mmi_imbalances_mtx_odd = create_truncated_gaussian_tensor(imbalance_mu, imbalance_sigma, (n_inputs, n_inputs//2-1))\n",
    "    mmi_imbalances_mtx_odd = 10**(mmi_imbalances_mtx_odd/10)\n",
    "\n",
    "    crossing_i_losses_mtx_odd = create_truncated_gaussian_tensor(i_loss_Crossing_mu, i_loss_Crossing_sigma, (n_inputs-2, n_inputs//2-1), 0)\n",
    "    crossing_i_losses_mtx_odd = 10**(crossing_i_losses_mtx_odd/10)\n",
    "    crossing_i_losses_mtx_odd_side = create_truncated_gaussian_tensor(i_loss_Crossing_mu, i_loss_Crossing_sigma, (n_inputs-2, n_inputs//2+1), 0)\n",
    "    crossing_i_losses_mtx_odd_side = 10**(crossing_i_losses_mtx_odd_side/10)\n",
    "    crossing_crosstalks_mtx_odd = create_truncated_gaussian_tensor(cross_talk_mu, cross_talk_sigma, (n_inputs-2, n_inputs//2-1))\n",
    "    crossing_crosstalks_mtx_odd = 10**(crossing_crosstalks_mtx_odd/10)\n",
    "    crossing_crosstalks_mtx_odd_side = create_truncated_gaussian_tensor(cross_talk_mu, cross_talk_sigma, (n_inputs-2, n_inputs//2+1))\n",
    "    crossing_crosstalks_mtx_odd_side = 10**(crossing_crosstalks_mtx_odd_side/10)\n",
    "\n",
    "    if name_model == Clements_Arct:\n",
    "        model = Clements_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            pc_i_losses_mtx_even=pc_i_losses_mtx_even,\n",
    "            pc_i_losses_mtx_odd=pc_i_losses_mtx_odd,\n",
    "            pc_i_losses_mtx_inout=pc_i_losses_mtx_inout,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_i_losses_mtx_odd=mmi_i_losses_mtx_odd,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            mmi_imbalances_mtx_odd=mmi_imbalances_mtx_odd,\n",
    "            pc_loss_dB_max=pc_loss_dB_max,\n",
    "            N_bits=N_bits,\n",
    "            phase_shift_noise_std=phase_shift_noise_std)\n",
    "    elif name_model == Fldzhyan_Arct:\n",
    "        model = Fldzhyan_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            pc_i_losses_mtx_even=pc_i_losses_mtx_even,\n",
    "            pc_i_losses_mtx_odd=pc_i_losses_mtx_odd,\n",
    "            pc_i_losses_mtx_inout=pc_i_losses_mtx_inout,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_i_losses_mtx_odd=mmi_i_losses_mtx_odd,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            mmi_imbalances_mtx_odd=mmi_imbalances_mtx_odd,\n",
    "            pc_loss_dB_max=pc_loss_dB_max,\n",
    "            N_bits=N_bits,\n",
    "            phase_shift_noise_std=phase_shift_noise_std)\n",
    "    elif name_model == NEUROPULSCrossingSide_Arct:\n",
    "        model = NEUROPULSCrossingSide_Arct(\n",
    "            n_inputs=n_inputs,\n",
    "            pc_i_losses_mtx_even=pc_i_losses_mtx_even,\n",
    "            pc_i_losses_mtx_inout=pc_i_losses_mtx_even,\n",
    "            mmi_i_losses_mtx_even=mmi_i_losses_mtx_even,\n",
    "            mmi_imbalances_mtx_even=mmi_imbalances_mtx_even,\n",
    "            crossing_i_losses_mtx_odd=crossing_i_losses_mtx_odd_side,\n",
    "            crossing_crosstalks_mtx_odd=crossing_crosstalks_mtx_odd_side,\n",
    "            pc_loss_dB_max=pc_loss_dB_max,\n",
    "            N_bits=N_bits,\n",
    "            phase_shift_noise_std=phase_shift_noise_std)\n",
    "    else:\n",
    "        model = None\n",
    "        raise Exception('Something not good on the input')\n",
    "    return model\n",
    "\n",
    "# Fidelity and Loss function --------------------------------------------------------------------------------------\n",
    "def FidelityUnitary(predicted_matrix, target_matrix):\n",
    "    n_inputs = predicted_matrix.shape[0]\n",
    "    predicted_matrix = predicted_matrix.to(torch.complex128)\n",
    "    target_matrix = target_matrix.to(torch.complex128)\n",
    "    Frobenius_module_p = torch.trace(torch.matmul(predicted_matrix.t().conj(), predicted_matrix))\n",
    "    Frobenius_pt = torch.trace(torch.matmul(predicted_matrix.t().conj(), target_matrix))\n",
    "    cosine_similarity = (torch.abs(Frobenius_pt))**2/(n_inputs*Frobenius_module_p)\n",
    "    Fidelity = torch.abs(cosine_similarity)\n",
    "    return Fidelity\n",
    "\n",
    "def Loss_FildelityUnitary(predicted_matrix, target_matrix):\n",
    "    fidelity = FidelityUnitary(predicted_matrix, target_matrix)\n",
    "    return 1 - fidelity\n",
    "\n",
    "# Calculate the prediction ----------------------------------------------------------------------------------------\n",
    "def model_training(model, optimizer, target_matrix):\n",
    "    for _ in range(n_epochs):     # Optimiziation with gradient\n",
    "        pred_matrix = model()\n",
    "        loss = Loss_FildelityUnitary(pred_matrix, target_matrix)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Get fidelity\n",
    "    with torch.no_grad():\n",
    "        pred_matrix = model()\n",
    "        fidelity = FidelityUnitary(pred_matrix, target_matrix)\n",
    "    return fidelity, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdd8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [02:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m         model \u001b[38;5;241m=\u001b[39m select_model(model_obj)\n\u001b[0;32m     16\u001b[0m         optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m---> 17\u001b[0m         last_fidelity, model \u001b[38;5;241m=\u001b[39m model_training(model, optimizer, targets[idx_targ, : , :])\n\u001b[0;32m     18\u001b[0m         fidelities\u001b[38;5;241m.\u001b[39mappend(last_fidelity)\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;66;03m# chagne the phase shift gradually to see effect on fidelity\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Save the results model ======================================================================================\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create folder and retun the directory:\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 106\u001b[0m, in \u001b[0;36mmodel_training\u001b[1;34m(model, optimizer, target_matrix)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_training\u001b[39m(model, optimizer, target_matrix):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):     \u001b[38;5;66;03m# Optimiziation with gradient\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m         pred_matrix \u001b[38;5;241m=\u001b[39m model()\n\u001b[0;32m    107\u001b[0m         loss \u001b[38;5;241m=\u001b[39m Loss_FildelityUnitary(pred_matrix, target_matrix)\n\u001b[0;32m    108\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\femarche\\.conda\\envs\\torch_NP2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\femarche\\OneDrive - UGent\\Documents\\4_Archives\\PhD_untilBraidPaper\\NP_Architecture_Paper\\Code_Architecture_Paper\\20251010_OFC_Conference\\test_03_PCMPhaseLoss\\models\\unitary_matrix_models.py:91\u001b[0m, in \u001b[0;36mClements_Arct.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m     arct_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pc_layer_odd[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi](arct_matrix)\n\u001b[0;32m     90\u001b[0m     arct_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmi_layer_odd[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi](arct_matrix)\n\u001b[1;32m---> 91\u001b[0m     arct_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pc_layer_odd[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m](arct_matrix)\n\u001b[0;32m     92\u001b[0m     arct_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmi_layer_odd[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m](arct_matrix)\n\u001b[0;32m     93\u001b[0m arct_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pc_layer_out(arct_matrix)\n",
      "File \u001b[1;32mc:\\Users\\femarche\\.conda\\envs\\torch_NP2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\femarche\\OneDrive - UGent\\Documents\\4_Archives\\PhD_untilBraidPaper\\NP_Architecture_Paper\\Code_Architecture_Paper\\20251010_OFC_Conference\\test_03_PCMPhaseLoss\\models\\photonic_components\\PhaseChangers_layers.py:205\u001b[0m, in \u001b[0;36mPCLayerMatrix_Odd.forward\u001b[1;34m(self, x_matrix)\u001b[0m\n\u001b[0;32m    203\u001b[0m phase_shift_quantized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdac(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphase_shift)\n\u001b[0;32m    204\u001b[0m Transmission \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphaL \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m phase_shift_quantized)\n\u001b[1;32m--> 205\u001b[0m layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, Transmission\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m1.\u001b[39mj\u001b[38;5;241m*\u001b[39mphase_shift_quantized), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =================================================================================================================\n",
    "# =============================================== MAIN ============================================================\n",
    "# =================================================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the right data\n",
    "    index_matrix = run_index % n_CPU_X_sim\n",
    "    targets = load_targets(index_matrix)\n",
    "\n",
    "    # Simulations\n",
    "    fidelities = []\n",
    "    n_targets = targets.shape[0]\n",
    "    for idx_targ in tqdm.trange(n_targets):\n",
    "        for rep in range(n_repetitions):\n",
    "            # Initialize new model with different initial phase shifts for each simulaiton\n",
    "            model = select_model(model_obj)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            last_fidelity, model = model_training(model, optimizer, targets[idx_targ, : , :])\n",
    "            fidelities.append(last_fidelity)\n",
    "\n",
    "            # chagne the phase shift gradually to see effect on fidelity\n",
    "    \n",
    "    # Save the results model ======================================================================================\n",
    "    # Create folder and retun the directory:\n",
    "    base_dir = \"./outdata/\"\n",
    "    # Create the new run directory\n",
    "    run_dir = os.path.join(base_dir, f'run{num_folder}')\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    # Create the full path\n",
    "    filename = f'simulation_{run_index}.pt'\n",
    "    full_path = os.path.join(run_dir, filename)\n",
    "    # Create a dictionary\n",
    "    save_dict = {\n",
    "        'model_name': model_obj.__name__,\n",
    "        'run_index': run_index,\n",
    "        'fidelities': fidelities,\n",
    "    }\n",
    "    # Save it\n",
    "    torch.save(save_dict, full_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    work_duration = end_time - start_time\n",
    "    max_duration_human_readable = str(timedelta(seconds=work_duration))\n",
    "    print(f\"The maximum work duration is {max_duration_human_readable} (HH:MM:SS).\")\n",
    "    \n",
    "    print(\"Yeeeeh the code has finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d1b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_NP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
