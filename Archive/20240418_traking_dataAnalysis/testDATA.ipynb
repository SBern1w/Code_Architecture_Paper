{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average and deviation std of the models for the loss\n",
    "The loss is the Mean Square Error, basicaly same stuff of Euclidean distance between two matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lastLoss(directory):\n",
    "    # Extract last loss from all the models\n",
    "    lastLoss_tuples = []\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)       # Construct the full file path\n",
    "        if os.path.isfile(file_path):       # Check if it is a file\n",
    "            result_sim = np.load(file_path, allow_pickle=True)\n",
    "            lastLoss_tuples.extend([(label, array[-1]) for label, array in result_sim if 'loss' in label])\n",
    "\n",
    "    # Creating df\n",
    "    return pd.DataFrame(lastLoss_tuples, columns=['label', 'value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_repmin_mean_devstd(df, name_models):\n",
    "    # Extracting the base label (e.g., 'LabelA', 'LabelB')\n",
    "    df['label_no_rep'] = df['label'].apply(lambda x: x.split('_rep')[0])\n",
    "    # Group with the base label and find min\n",
    "    min_lastLoss_s = df.groupby('label_no_rep')['value'].min()\n",
    "    # print(min_lastLoss_s)\n",
    "\n",
    "    mean_models= []\n",
    "    std_dev_models =[]\n",
    "    for name in name_models:\n",
    "        # take the same model \n",
    "        model_s = min_lastLoss_s[min_lastLoss_s.index.str.contains(name)]\n",
    "        mean_models.append(model_s.mean())\n",
    "        std_dev_models.append(model_s.std())\n",
    "    \n",
    "    return mean_models, std_dev_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_repmax_mean_devstd(df, name_models):\n",
    "    # Extracting the base label (e.g., 'LabelA', 'LabelB')\n",
    "    df['label_no_rep'] = df['label'].apply(lambda x: x.split('_rep')[0])\n",
    "    # Group with the base label and find min\n",
    "    max_lastLoss_s = df.groupby('label_no_rep')['value'].max()\n",
    "    # print(min_lastLoss_s)\n",
    "\n",
    "    mean_models= []\n",
    "    std_dev_models =[]\n",
    "    for name in name_models:\n",
    "        # take the same model \n",
    "        model_s = max_lastLoss_s[max_lastLoss_s.index.str.contains(name)]\n",
    "        mean_models.append(model_s.mean())\n",
    "        std_dev_models.append(model_s.std())\n",
    "    \n",
    "    return mean_models, std_dev_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 66.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example: 6x6 full matrix and three 2x2 blocks\n",
    "N = 2000\n",
    "blocks = [torch.randn(2, 2) for _ in range(N // 2)]\n",
    "full_matrix = torch.randn(N, N)\n",
    "\n",
    "# Prepare batches\n",
    "block_tensor = torch.stack(blocks)  # Shape: [3, 2, 2]\n",
    "# Extract corresponding 2-row segments from the full matrix\n",
    "segment_tensor = torch.stack([full_matrix[2*i:2*i+2] for i in range(N // 2)])  # Shape: [3, 2, N]\n",
    "\n",
    "# Batch matrix multiplication\n",
    "for _ in tqdm.trange(1000):\n",
    "    result = torch.bmm(block_tensor, segment_tensor)  # Result shape: [3, 2, N]\n",
    "\n",
    "    # Assemble the result back into the full result matrix if needed\n",
    "    result_matrix = torch.zeros_like(full_matrix)\n",
    "    for i in range(result.shape[0]):\n",
    "        result_matrix[2*i:2*i+2, :] = result[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 87.43it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example blocks and full matrix\n",
    "blocks = [torch.randn(2, 2) for _ in range(N // 2)]  # List of 2x2 blocks\n",
    "full_matrix = torch.randn(N, N)\n",
    "\n",
    "# Result matrix initialized to zero\n",
    "result = torch.zeros_like(full_matrix)\n",
    "\n",
    "for _ in tqdm.trange(1000):\n",
    "    # Apply each block to the corresponding submatrix of the full matrix\n",
    "    for i, block in enumerate(blocks):\n",
    "        start_index = 2 * i\n",
    "        result[start_index:start_index+2, :] = block @ full_matrix[start_index:start_index+2, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4425+0.j, -2.1900+0.j, -4.9393+0.j, -0.9951+0.j],\n",
      "        [ 3.7451+0.j, -3.3581+0.j, -7.5736+0.j, -1.5257+0.j],\n",
      "        [-0.9441+0.j, -1.5235+0.j, -1.2227+0.j,  1.0526+0.j],\n",
      "        [ 1.2589+0.j,  2.0313+0.j,  1.6302+0.j, -1.4035+0.j]])\n"
     ]
    }
   ],
   "source": [
    "# Define the size of your matrices\n",
    "n = 4  # for a 4x4 matrix\n",
    "\n",
    "# Create a full matrix\n",
    "torch.manual_seed(37)\n",
    "full_matrix = 1j*torch.randn(n, n)\n",
    "\n",
    "# Create a sparse matrix with elements only at specified indices\n",
    "sparse_matrix = 1j*torch.zeros(n, n)\n",
    "# Assign values to specified indices\n",
    "sparse_matrix[0, 0] = 1j*1.5  # example value\n",
    "sparse_matrix[1, 0] = 1j*2.3  # example value\n",
    "sparse_matrix[2, 2] = 1j*-0.6 # example value\n",
    "sparse_matrix[3, 2] = 1j*0.8  # example value\n",
    "\n",
    "sparse_matrix[0, 1] = 1j*1.5*1.65  # example value\n",
    "sparse_matrix[1, 1] = 1j*2.3*1.65  # example value\n",
    "sparse_matrix[2, 3] = 1j*-0.6*1.65 # example value\n",
    "sparse_matrix[3, 3] = 1j*0.8*1.65  # example value\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "result = sparse_matrix @ full_matrix\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4425+0.j, -2.1900+0.j, -4.9393+0.j, -0.9951+0.j],\n",
       "        [ 3.7451+0.j, -3.3581+0.j, -7.5736+0.j, -1.5257+0.j],\n",
       "        [-0.9441+0.j, -1.5235+0.j, -1.2227+0.j,  1.0526+0.j],\n",
       "        [ 1.2589+0.j,  2.0313+0.j,  1.6302+0.j, -1.4035+0.j]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_elements1 = torch.tensor([1j*1.5, 1j*2.3, 1j*-0.6, 1j*0.8])\n",
    "diag_elements2 = torch.tensor([1j*1.5, 1j*2.3, 1j*-0.6, 1j*0.8])*1.65\n",
    "\n",
    "\n",
    "# Create a new matrix by copying even rows into odd rows\n",
    "even_indices_values = full_matrix[0::2]\n",
    "new_matrix1 = full_matrix.clone()  # Clone the original matrix to preserve it\n",
    "# new_matrix1[1::2] = new_matrix1[0::2]  # Copy even rows into odd rows\n",
    "new_matrix1[1::2] = even_indices_values\n",
    "\n",
    "result1 = diag_elements1.view(-1, 1) * new_matrix1\n",
    "\n",
    "new_matrix2 = full_matrix.clone()  # Clone the original matrix to preserve it\n",
    "new_matrix2[:-1:2] = new_matrix2[1::2]\n",
    "\n",
    "result2 = diag_elements2.view(-1, 1) * new_matrix2\n",
    "\n",
    "result = result1 + result2\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "class mlayer_MMIs_odd(nn.Module):\n",
    "    r\"\"\" Create odd MMIs matrix\n",
    "    0______0\n",
    "\n",
    "    1__  __1\n",
    "       \\/\n",
    "    2__/\\__2\n",
    "    \n",
    "    3______3\n",
    "    \"\"\"\n",
    "    def __init__(self, N: int,\n",
    "                 insertion_loss_MMI: torch.Tensor,          # Dimension should be N//2\n",
    "                 imbalance_MMI: torch.Tensor):\n",
    "        \n",
    "        if N%2 == 1: Exception('N is odd!!! NONONO, put it even!!!')\n",
    "        self.N = N\n",
    "        \n",
    "        attenuation = torch.sqrt(1-insertion_loss_MMI)          # They are in vector format\n",
    "        MMI11 = attenuation*torch.sqrt(1/2+imbalance_MMI)\n",
    "        MMI12 = attenuation*1.j*torch.sqrt(1/2-imbalance_MMI)\n",
    "        MMI21 = attenuation*1.j*torch.sqrt(1/2-imbalance_MMI)\n",
    "        MMI22 = attenuation*torch.sqrt(1/2+imbalance_MMI)\n",
    "        \n",
    "        self._diag1 = torch.zeros(N, dtype=torch.cfloat)\n",
    "        self._diag2 = torch.zeros(N, dtype=torch.cfloat)\n",
    "        self._diag1[0] = 1\n",
    "        self._diag1[-1] = 1\n",
    "        for i in range(1, N-1, 2):\n",
    "            print(i)\n",
    "            self._diag1[i] = MMI11[i//2]\n",
    "            self._diag1[i+1] = MMI12[i//2]\n",
    "            self._diag2[i] = MMI21[i//2]\n",
    "            self._diag2[i+1] = MMI22[i//2]\n",
    "\n",
    "N = 6\n",
    "insertion_loss_MMI = torch.Tensor([0 for _ in range(N//2)])\n",
    "imbalance_MMI = torch.Tensor([0 for _ in range(N//2)])\n",
    "\n",
    "cioa = mlayer_MMIs_odd(N, insertion_loss_MMI, imbalance_MMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix Shape: torch.Size([6, 6])\n",
      "Reshaped Matrix Shape: torch.Size([3, 2, 6])\n",
      "tensor([[ 0.7838, -0.7593,  0.6416,  0.3753,  0.8976, -0.5454],\n",
      "        [ 1.2951,  0.0497,  2.5351, -0.1539,  0.1379,  1.3129],\n",
      "        [-0.5484, -0.5114, -1.0520, -0.0981,  0.2616,  0.4543],\n",
      "        [ 0.7163,  1.2418,  1.6048,  0.1609,  0.9362,  0.1414],\n",
      "        [ 1.8085, -0.1083,  1.9048, -0.0193, -0.2414, -2.1111],\n",
      "        [ 1.7789,  0.0567, -0.1200,  0.7928, -1.2071,  0.0577]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the size of the original square matrix\n",
    "N = 6\n",
    "\n",
    "# Create a sample NxN matrix\n",
    "original_matrix = torch.randn(N, N)\n",
    "\n",
    "# Reshape the original matrix into the desired shape\n",
    "reshaped_matrix = original_matrix.view(N // 2, 2, N)\n",
    "\n",
    "print(\"Original Matrix Shape:\", original_matrix.shape)\n",
    "print(\"Reshaped Matrix Shape:\", reshaped_matrix.shape)\n",
    "print(original_matrix)\n",
    "\n",
    "\n",
    "orig = reshaped_matrix.view(original_matrix.shape[0], -1)\n",
    "original_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 5., 8.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a 2D array\n",
    "mmi_i_losses_matrix = torch.Tensor([[1, 2, 3],\n",
    "                                [4, 5, 6],\n",
    "                                [7, 8, 9]])\n",
    "\n",
    "# Select the 2nd column (remember, Python uses zero-based indexing)\n",
    "selected_column = mmi_i_losses_matrix[:, 1]\n",
    "\n",
    "print(selected_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000+0.j, 0.6000+0.j, 0.7000+0.j, 0.8000+0.j])\n",
      "tensor([4.+0.j, 3.+0.j, 2.+0.j, 1.+0.j])\n",
      "tensor([[[0.5000+0.j, 4.0000+0.j],\n",
      "         [4.0000+0.j, 0.5000+0.j]],\n",
      "\n",
      "        [[0.6000+0.j, 3.0000+0.j],\n",
      "         [3.0000+0.j, 0.6000+0.j]],\n",
      "\n",
      "        [[0.7000+0.j, 2.0000+0.j],\n",
      "         [2.0000+0.j, 0.7000+0.j]],\n",
      "\n",
      "        [[0.8000+0.j, 1.0000+0.j],\n",
      "         [1.0000+0.j, 0.8000+0.j]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assume _n_mmi, atten, tau, and kappa are defined as:\n",
    "_n_mmi = 10  # example size\n",
    "atten = torch.tensor([0.5, 0.6, 0.7, 0.8])  # example attenuation values\n",
    "tau = torch.tensor([4.0, 3.0, 2.0, 1.0])    # example tau values\n",
    "kappa = torch.tensor([1.0, 1.1, 1.2, 1.3])\n",
    "\n",
    "# Calculate the components\n",
    "# Create the elements for the matrix\n",
    "a = atten + 0.j\n",
    "b = tau + 0.j\n",
    "\n",
    "conn = torch.zeros(4)\n",
    "conn[0] = 1\n",
    "\n",
    "\n",
    "mmi_elements = torch.stack([\n",
    "    torch.stack([a, b], dim=-1),\n",
    "    torch.stack([b, a], dim=-1)\n",
    "], dim=-2)\n",
    "\n",
    "# mmi_elements = torch.stack([[a, b],\n",
    "#                             [b, a]], dim=-2)\n",
    "\n",
    "\n",
    "stak1 = torch.stack([a, b], dim=-1),\n",
    "# Expand to _n_mmi batches and reshape\n",
    "# _mmis = mmi_elements.expand(_n_mmi, 2, 2)\n",
    "\n",
    "# Output the _mmis tensor\n",
    "print(a)\n",
    "print(b)\n",
    "print(mmi_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m conn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Use * to unpack the list of tensors into the function\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m block_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mblock_diag([\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39mmmi_elements)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(mmi_elements)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(block_matrix)\n",
      "File \u001b[1;32mc:\\Users\\femarche\\.conda\\envs\\torch_NP2\\Lib\\site-packages\\torch\\functional.py:1173\u001b[0m, in \u001b[0;36mblock_diag\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(block_diag, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\u001b[38;5;241m.\u001b[39mblock_diag(tensors)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example of dynamically creating a list of matrices\n",
    "matrices = []\n",
    "for i in range(1, 5):  # Dynamically deciding the number of matrices\n",
    "    matrices.append(torch.tensor([[i, i+1], [i+2, i+3]]))\n",
    "\n",
    "conn = torch.zeros(4)\n",
    "conn = torch.Tensor([1])\n",
    "# Use * to unpack the list of tensors into the function\n",
    "block_matrix = torch.block_diag(conn, *mmi_elements)\n",
    "\n",
    "print(mmi_elements)\n",
    "print(block_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1, 200,   3, 400])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = torch.tensor([True, False, True, False])\n",
    "\n",
    "# Tensors from which to choose values\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y = torch.tensor([100, 200, 300, 400])\n",
    "\n",
    "# Using torch.where\n",
    "result = torch.where(condition, x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 2])\n",
      "tensor([  1, 200,   1, 200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tensors x and y, each with 2 elements\n",
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([100, 200])\n",
    "\n",
    "# Condition tensor, tailored to match a repeated scenario\n",
    "condition = torch.tensor([True, False])\n",
    "\n",
    "# Repeat x, y, and condition to make the length 4\n",
    "x_repeated = x.repeat(2)  # Repeats the entire tensor\n",
    "y_repeated = y.repeat(2)\n",
    "condition_repeated = condition.repeat(2)  # [True, False, True, False]\n",
    "\n",
    "# Use torch.where to select values based on the condition\n",
    "result = torch.where(condition_repeated, x_repeated, y_repeated)\n",
    "\n",
    "print(x_repeated)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_NP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
